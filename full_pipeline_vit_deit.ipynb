{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e73784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from tempfile import gettempdir\n",
    "\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace, average_displacement_error_mean, rmse\n",
    "\n",
    "from src.utils import load_config, get_model_class\n",
    "# from src.dataset import load_datasets\n",
    "from src.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "CONFIG_PATH = \"models/configs/vit_deit_config.yaml\"\n",
    "MODEL_NAME = \"ViTDeitModel\"  # name of model file in models/\n",
    "EXP_NAME = \"notebook_exp_vit_deit\"\n",
    "EXP_NUM = 0  # which epoch to load for evaluation/vis\n",
    "\n",
    "# Load config\n",
    "cfg = load_config(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "exp_dir = os.path.join(\"experiments\", EXP_NAME)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "ckpt_path = os.path.join(exp_dir, f\"epoch_{EXP_NUM}.pth\")\n",
    "pred_path = os.path.join(exp_dir, f\"predictions_{EXP_NUM}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"../data/lyft-motion-prediction-autonomous-vehicles\"\n",
    "dm = LocalDataManager(None)\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], batch_size=train_cfg[\"batch_size\"], \n",
    "                             num_workers=0)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8548429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of training batches: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "eval_zarr = ChunkedDataset(dm.require(eval_cfg[\"key\"])).open()\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer)\n",
    "eval_dataloader = DataLoader(eval_dataset, shuffle=eval_cfg[\"shuffle\"], batch_size=eval_cfg[\"batch_size\"], \n",
    "                             num_workers=0)\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "ModelClass = get_model_class(MODEL_NAME)\n",
    "model = ModelClass(cfg)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "print(list(model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85352c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (only if checkpoint doesn't exist)\n",
    "losses_train = []\n",
    "if not os.path.exists(ckpt_path):\n",
    "    print(f\"Checkpoint not found at {ckpt_path}, training model...\")\n",
    "    trainer = Trainer(cfg, model, device, train_dataloader, exp_name=EXP_NAME)\n",
    "    # losses_train = trainer.train(EXP_NUM)\n",
    "    losses_train, losses_val_epoch, losses_train_epoch = trainer.train_and_validate(eval_dataloader, EXP_NUM)\n",
    "else:\n",
    "    print(f\"Loading existing checkpoint: {ckpt_path}\")\n",
    "    model.load_state_dict(torch.load(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if losses_train:\n",
    "    plt.plot(np.arange(len(losses_train)), losses_train, label=\"train loss\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Time\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if losses_train_epoch:\n",
    "    plt.plot(np.arange(len(losses_train_epoch)), losses_train_epoch, label=\"train loss (epoch)\")\n",
    "    plt.plot(np.arange(len(losses_train_epoch)), losses_val_epoch, label=\"val loss (epoch)\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adf36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save losses as npy file\n",
    "losses_train_path = os.path.join(exp_dir, f\"losses_train_{EXP_NUM}.npy\")\n",
    "losses_train_epoch_path = os.path.join(exp_dir, f\"losses_train_epoch_{EXP_NUM}.npy\")\n",
    "losses_val_epoch_path = os.path.join(exp_dir, f\"losses_val_{EXP_NUM}.npy\")\n",
    "\n",
    "np.save(losses_train_path, losses_train)\n",
    "np.save(losses_train_epoch_path, losses_train_epoch)\n",
    "np.save(losses_val_epoch_path, losses_val_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c414be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== GENERATE AND LOAD CHOPPED TEST DATASET\n",
    "num_frames_to_chop = 100\n",
    "test_cfg = cfg[\"test_data_loader\"]\n",
    "test_base_path = create_chopped_dataset(dm.require(test_cfg[\"key\"]), cfg[\"raster_params\"][\"filter_agents_threshold\"],\n",
    "                              num_frames_to_chop, cfg[\"model_params\"][\"future_num_frames\"], MIN_FUTURE_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_zarr_path = str(Path(test_base_path) / Path(dm.require(test_cfg[\"key\"])).name)\n",
    "test_mask_path = str(Path(test_base_path) / \"mask.npz\")\n",
    "test_gt_path = str(Path(test_base_path) / \"gt.csv\")\n",
    "\n",
    "test_zarr = ChunkedDataset(test_zarr_path).open()\n",
    "test_mask = np.load(test_mask_path)[\"arr_0\"]\n",
    "# ===== INIT TEST DATASET AND LOAD MASK\n",
    "test_dataset = AgentDataset(cfg, test_zarr, rasterizer, agents_mask=test_mask)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=test_cfg[\"shuffle\"], batch_size=test_cfg[\"batch_size\"], \n",
    "                             num_workers=0)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# ==== EVAL LOOP\n",
    "def evaluate_model(model, test_dataloader, device, pred_path):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    # store information for evaluation\n",
    "    future_coords_offsets_pd = []\n",
    "    timestamps = []\n",
    "    agent_ids = []\n",
    "\n",
    "    progress_bar = tqdm(test_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for data in progress_bar:\n",
    "            _, outputs = model.forward_pass(data, device, criterion)\n",
    "\n",
    "            # convert agent coordinates into world offsets\n",
    "            agents_coords = outputs.cpu().numpy()\n",
    "            world_from_agents = data[\"world_from_agent\"].numpy()\n",
    "            centroids = data[\"centroid\"].numpy()\n",
    "            coords_offset = transform_points(agents_coords, world_from_agents) - centroids[:, None, :2]\n",
    "            \n",
    "            future_coords_offsets_pd.append(np.stack(coords_offset))\n",
    "            timestamps.append(data[\"timestamp\"].numpy().copy())\n",
    "            agent_ids.append(data[\"track_id\"].numpy().copy())\n",
    "    \n",
    "    write_pred_csv(pred_path,\n",
    "               timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(future_coords_offsets_pd),\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75fabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation (only if prediction doesn't exist)\n",
    "if not os.path.exists(pred_path):\n",
    "    print(f\"Predictions not found at {pred_path}, evaluating model...\")\n",
    "    evaluate_model(model, test_dataloader, device, pred_path)\n",
    "else:\n",
    "    print(f\"Loading existing predictions: {pred_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics_csv(test_gt_path, pred_path, [neg_multi_log_likelihood, time_displace, average_displacement_error_mean, rmse])\n",
    "for metric_name, metric_mean in metrics.items():\n",
    "    print(metric_name, metric_mean)\n",
    "\n",
    "# save metrics as csv without pandas\n",
    "with open(os.path.join(exp_dir, f\"metrics_{EXP_NUM}.csv\"), \"w\") as f:\n",
    "    f.write(\"metric,mean\\n\")\n",
    "    for metric_name, metric_mean in metrics.items():\n",
    "        f.write(f\"{metric_name},{metric_mean}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# build a dict to retrieve future trajectories from GT\n",
    "gt_rows = {}\n",
    "for row in read_gt_csv(test_gt_path):\n",
    "    gt_rows[row[\"track_id\"] + row[\"timestamp\"]] = row[\"coord\"]\n",
    "\n",
    "test_ego_dataset = EgoDataset(cfg, test_dataset.dataset, rasterizer)\n",
    "\n",
    "for frame_number in range(99, len(test_zarr.frames), 100):  # start from last frame of scene_0 and increase by 100\n",
    "    agent_indices = test_dataset.get_frame_indices(frame_number) \n",
    "    if not len(agent_indices):\n",
    "        continue\n",
    "\n",
    "    # get AV point-of-view frame\n",
    "    data_ego = test_ego_dataset[frame_number]\n",
    "    im_ego = rasterizer.to_rgb(data_ego[\"image\"].transpose(1, 2, 0))\n",
    "    center = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n",
    "    \n",
    "    predicted_positions = []\n",
    "    target_positions = []\n",
    "\n",
    "    for v_index in agent_indices:\n",
    "        print(f\"Processing agent {v_index} in frame {frame_number}\")\n",
    "        data_agent = test_dataset[v_index]\n",
    "\n",
    "        out_net = model(torch.from_numpy(data_agent[\"image\"]).unsqueeze(0).to(device))\n",
    "        out_pos = out_net[0].reshape(-1, 2).detach().cpu().numpy()\n",
    "        # store absolute world coordinates\n",
    "        predicted_positions.append(transform_points(out_pos, data_agent[\"world_from_agent\"]))\n",
    "        # retrieve target positions from the GT and store as absolute coordinates\n",
    "        track_id, timestamp = data_agent[\"track_id\"], data_agent[\"timestamp\"]\n",
    "        target_positions.append(gt_rows[str(track_id) + str(timestamp)] + data_agent[\"centroid\"][:2])\n",
    "\n",
    "\n",
    "    # convert coordinates to AV point-of-view so we can draw them\n",
    "    predicted_positions = transform_points(np.concatenate(predicted_positions), data_ego[\"raster_from_world\"])\n",
    "    target_positions = transform_points(np.concatenate(target_positions), data_ego[\"raster_from_world\"])\n",
    "\n",
    "    draw_trajectory(im_ego, predicted_positions, PREDICTED_POINTS_COLOR)\n",
    "    draw_trajectory(im_ego, target_positions, TARGET_POINTS_COLOR)\n",
    "\n",
    "    plt.imshow(im_ego)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lilach_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
